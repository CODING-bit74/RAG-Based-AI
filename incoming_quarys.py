import requests
import joblib
import numpy as np
import sys
import time
import os
from sklearn.metrics.pairwise import cosine_similarity

# ============================================================
# ğŸ§© Create Embedding Function
# ============================================================
def create_embedding(text):
    try:
        response = requests.post("http://localhost:11434/api/embeddings", json={
            "model": "bge-m3",
            "prompt": text
        })
        response.raise_for_status()
        return response.json()["embedding"]
    except Exception as e:
        print(f"âŒ Embedding Error: {e}")
        return None

# ============================================================
# ğŸ’¬ Generate AI Response (RAG + Intent + Memory)
# ============================================================
def generate_response(memory, context, question, use_context=True, summarize=False):
    q_lower = question.lower()

    # ğŸ¯ 1ï¸âƒ£ Intent: Generate Questions Mode
    if any(word in q_lower for word in ["question", "quiz", "mcq", "interview"]):
        prompt = f"""
You are AppsterGPT â€” a professional AI developed by Arpit Kumar Mishra.
Generate 10â€“15 **clear and relevant questions** about:
"{question}"

Guidelines:
- Mix beginner and advanced levels.
- Use a numbered list.
- Add hints or subtopics in parentheses if useful.

Answer:
"""

    # ğŸ§  2ï¸âƒ£ Intent: Summarization Mode
    elif summarize:
        prompt = f"""
You are AppsterGPT â€” a summarization expert AI built by Arpit Kumar Mishra.
Your task is to create a **concise summary** of the conversation below.

Keep only key facts, important context, and user preferences.
Make it natural and readable, like a short memory summary.

Conversation:
{memory}

Summary:
"""

    # ğŸ’¡ 3ï¸âƒ£ Normal RAG or General QA Mode
    else:
        context_part = f"\nContext:\n{context}\n" if use_context and context.strip() else ""
        memory_part = f"\nConversation Memory:\n{memory}\n" if memory.strip() else ""

        prompt = f"""
You are AppsterGPT â€” a highly advanced AI assistant created by Arpit Kumar Mishra.
Use both the retrieved context and conversation memory to give a clear, natural, and structured answer.

{memory_part}
{context_part}

Question: {question}

Answer in detail, with examples or bullet points where helpful:
"""

    payload = {"model": "llama3", "prompt": prompt, "stream": False}

    try:
        response = requests.post("http://localhost:11434/api/generate", json=payload)
        response.raise_for_status()
        return response.json().get("response", "").strip()
    except Exception as e:
        print(f"âŒ Generation Error: {e}")
        return "Sorry, I couldnâ€™t generate a response right now."

# ============================================================
# ğŸï¸ Typing Effect
# ============================================================
def type_effect(text, delay=0.02):
    for char in text:
        sys.stdout.write(char)
        sys.stdout.flush()
        time.sleep(delay)
    print()

# ============================================================
# ğŸ’¾ Memory Handling
# ============================================================
HISTORY_FILE = "chat_history.txt"

def load_memory():
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            memory = f.read().strip()
        print("ğŸ§  Loaded previous chat history.")
        return memory
    else:
        print("âš ï¸ Starting new session (no history found).")
        return ""

def save_memory(memory):
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        f.write(memory.strip())

# ============================================================
# ğŸ“Š Load Embeddings
# ============================================================
try:
    df = joblib.load("embeddings.joblib")
    print("âœ… Embeddings loaded successfully!")
except Exception as e:
    print(f"âŒ Failed to load embeddings: {e}")
    sys.exit(1)

# ============================================================
# ğŸ§  Initialize Memory
# ============================================================
conversation_memory = load_memory()

# ============================================================
# ğŸ’¬ Chat Loop
# ============================================================
print("\nğŸš€ Welcome to AppsterGPT (by Arpit Kumar Mishra)!")
print("Type 'exit' to quit or 'clear memory' to reset history.\n")

while True:
    question = input("\nğŸ’¬ You: ").strip()

    if question.lower() in ["exit", "quit"]:
        print("\nğŸ’¾ Saving memory before exit...")
        save_memory(conversation_memory)
        print("âœ… Memory saved.")
        print("ğŸ‘‹ Goodbye from AppsterGPT! Have a great day!\n")
        break

    if question.lower() in ["clear memory", "reset"]:
        conversation_memory = ""
        save_memory(conversation_memory)
        print("ğŸ§¹ Memory cleared successfully!")
        continue

    # ğŸ§© Create embedding
    query_embedding = create_embedding(question)
    if query_embedding is None:
        continue

    # ğŸ§® RAG similarity
    similarity = cosine_similarity(np.vstack(df['embedding']), [query_embedding]).flatten()
    top_indices = similarity.argsort()[::-1][:5]
    top_chunks = df.iloc[top_indices]["text"].tolist()

    context = "\n\n".join(top_chunks)
    max_sim = float(similarity[top_indices[0]])
    use_context = max_sim > 0.45

    # ğŸ§  Check if memory is too large
    if len(conversation_memory.split()) > 1200:
        print("\nğŸ§© Memory too long â€” summarizing...\n")
        summary = generate_response(conversation_memory, "", "Summarize memory", summarize=True)
        conversation_memory = summary
        save_memory(conversation_memory)
        print("âœ… Memory summarized successfully!\n")

    # ğŸ¤– Generate answer
    answer = generate_response(conversation_memory, context, question, use_context=use_context)

    # ğŸ§  Update memory
    conversation_memory += f"\nUser: {question}\nAppsterGPT: {answer}\n"
    save_memory(conversation_memory)

    # ğŸ—£ï¸ Display answer
    print("\nğŸ¤– AppsterGPT:\n")
    type_effect(answer)
    print("\n" + "-" * 60)
